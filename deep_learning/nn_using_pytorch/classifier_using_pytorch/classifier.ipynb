{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e161cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0552f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "import torch.nn as nn\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9087b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor = T.Compose([T.ToImage() , T.ToDtype(torch.float32 , scale=True)])\n",
    "\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\" , train=True , download=True , transform=toTensor\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\" , train=False , download=True , transform=toTensor\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data , valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data , [55_000 , 5_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c45841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data , shuffle=True , batch_size = 512 , pin_memory=True )\n",
    "valid_loader = DataLoader(valid_data , shuffle=True , batch_size = 512 , pin_memory=True)\n",
    "test_loader = DataLoader(test_data , shuffle=True , batch_size = 512 , pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b126f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample , y_sample = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f983d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c98748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5a6d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd33112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_valid_data.classes[y_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d48d73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouser Pullover Dress Coat Sandal Shirt Sneaker Bag Ankle boot "
     ]
    }
   ],
   "source": [
    "for i in range(1 , 10):\n",
    "    print(train_and_valid_data.classes[i] , end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c15e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bbb8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e2f8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model , metric , val_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch , y_batch in val_loader:\n",
    "            x_batch , y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            \n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            metric.update(y_pred , y_batch)\n",
    "            \n",
    "    return metric.compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_eval(model , train_loader , criterion , optimizer ,\n",
    "               val_loader , metric , n_epoch ):\n",
    "    \n",
    "    history = {\"train_loss\" : [] , \"train_metric(accuracy)\" : [] , \"val_metric(accuracy)\" : []}\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        metric.reset()\n",
    "        total_loss = 0\n",
    "        for x_batch , y_batch in train_loader:\n",
    "            #data\n",
    "            x_batch , y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            \n",
    "            #forward\n",
    "            \n",
    "            y_pred  = model(x_batch)\n",
    "            \n",
    "            #loss \n",
    "            \n",
    "            loss = criterion(y_pred , y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            #optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            metric.update(y_pred , y_batch)\n",
    "            \n",
    "        loss_mean = total_loss/len(train_loader)\n",
    "        \n",
    "        history[\"train_loss\"].append(loss_mean)\n",
    "        history[\"train_metric(accuracy)\"].append(metric.compute().item())\n",
    "        \n",
    "        history[\"val_metric(accuracy)\"].append(eval(model , metric , val_loader).item())\n",
    "        \n",
    "        print(f\"Epoch : {epoch + 1}/{n_epoch}, \"\n",
    "              f\"Train Loss : {history['train_loss'][-1]}, \"\n",
    "              f\"Train Metric ( Accuracy) : {history['train_metric(accuracy)'][-1]}, \"\n",
    "              f\"Val Metric (accuracy) : {history['val_metric(accuracy)'][-1]}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b5038ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/20, Train Loss : 1.406682523312392, Train Metric ( Accuracy) : 0.5595818161964417, Val Metric (accuracy) : 0.6424000263214111\n",
      "Epoch : 2/20, Train Loss : 0.7617398550113043, Train Metric ( Accuracy) : 0.7130545377731323, Val Metric (accuracy) : 0.7508000135421753\n",
      "Epoch : 3/20, Train Loss : 0.6311827169524299, Train Metric ( Accuracy) : 0.7703090906143188, Val Metric (accuracy) : 0.7767999768257141\n",
      "Epoch : 4/20, Train Loss : 0.5653285764985614, Train Metric ( Accuracy) : 0.7989272475242615, Val Metric (accuracy) : 0.8082000017166138\n",
      "Epoch : 5/20, Train Loss : 0.5227762217874881, Train Metric ( Accuracy) : 0.8143091201782227, Val Metric (accuracy) : 0.8184000253677368\n",
      "Epoch : 6/20, Train Loss : 0.49167994023473177, Train Metric ( Accuracy) : 0.826090931892395, Val Metric (accuracy) : 0.8270000219345093\n",
      "Epoch : 7/20, Train Loss : 0.4737724717016573, Train Metric ( Accuracy) : 0.8313272595405579, Val Metric (accuracy) : 0.8277999758720398\n",
      "Epoch : 8/20, Train Loss : 0.4532129082966734, Train Metric ( Accuracy) : 0.8374000191688538, Val Metric (accuracy) : 0.7997999787330627\n",
      "Epoch : 9/20, Train Loss : 0.44459800560165336, Train Metric ( Accuracy) : 0.8415818214416504, Val Metric (accuracy) : 0.8438000082969666\n",
      "Epoch : 10/20, Train Loss : 0.4270699413286315, Train Metric ( Accuracy) : 0.8477818369865417, Val Metric (accuracy) : 0.8432000279426575\n",
      "Epoch : 11/20, Train Loss : 0.4194272715184424, Train Metric ( Accuracy) : 0.8501636385917664, Val Metric (accuracy) : 0.8366000056266785\n",
      "Epoch : 12/20, Train Loss : 0.40726327813333935, Train Metric ( Accuracy) : 0.8552545309066772, Val Metric (accuracy) : 0.8378000259399414\n",
      "Epoch : 13/20, Train Loss : 0.39879963602180835, Train Metric ( Accuracy) : 0.8569090962409973, Val Metric (accuracy) : 0.8497999906539917\n",
      "Epoch : 14/20, Train Loss : 0.38835844590708063, Train Metric ( Accuracy) : 0.8600000143051147, Val Metric (accuracy) : 0.8447999954223633\n",
      "Epoch : 15/20, Train Loss : 0.3825460487493762, Train Metric ( Accuracy) : 0.8631272912025452, Val Metric (accuracy) : 0.8367999792098999\n",
      "Epoch : 16/20, Train Loss : 0.3748966411308006, Train Metric ( Accuracy) : 0.8653818368911743, Val Metric (accuracy) : 0.8537999987602234\n",
      "Epoch : 17/20, Train Loss : 0.368025004863739, Train Metric ( Accuracy) : 0.8683090806007385, Val Metric (accuracy) : 0.849399983882904\n",
      "Epoch : 18/20, Train Loss : 0.36134419645424243, Train Metric ( Accuracy) : 0.8696363568305969, Val Metric (accuracy) : 0.8479999899864197\n",
      "Epoch : 19/20, Train Loss : 0.35778535847310666, Train Metric ( Accuracy) : 0.8715999722480774, Val Metric (accuracy) : 0.8600000143051147\n",
      "Epoch : 20/20, Train Loss : 0.35009388128916424, Train Metric ( Accuracy) : 0.8737272620201111, Val Metric (accuracy) : 0.8622000217437744\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self , n_inputs , n_hidden1 , n_hidden2 , n_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_inputs , n_hidden1) , \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1 , n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2 , n_classes)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = ImageClassifier(n_inputs= 28 * 28 , n_hidden1=  300 , \n",
    "                        n_hidden2= 100 , n_classes= 10).to(device)\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "sentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr=learning_rate , momentum=0 )\n",
    "\n",
    "accuracy_metric = torchmetrics.Accuracy(task='multiclass' , num_classes=10).to(device)\n",
    "\n",
    "train_eval(model=model , \n",
    "           train_loader=train_loader,\n",
    "           criterion=sentropy,\n",
    "           optimizer=optimizer,\n",
    "           val_loader=valid_loader,\n",
    "           metric=accuracy_metric,\n",
    "           n_epoch=n_epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8be55cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([512, 1, 28, 28])\n",
      "torch.Size([3, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x_new , y_new = next(iter(valid_loader))\n",
    "\n",
    "print(len(valid_loader))\n",
    "print(x_new.shape)\n",
    "x_new = x_new[:3].to(device)\n",
    "print(x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e95c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1723,  0.4753, 11.2694,  1.2055,  3.4685, -5.5942,  4.1923, -6.8598,\n",
      "         -1.3340, -8.6228],\n",
      "        [ 3.0385,  6.3782,  0.6215,  8.9629,  1.0980, -9.0665, -1.5528, -2.3363,\n",
      "         -2.9354, -5.1512],\n",
      "        [-2.0960, -3.5928, -5.3018, -4.1145, -5.2092,  5.2536, -3.4882,  7.9512,\n",
      "          2.8521, 11.4585]], device='cuda:0')\n",
      "tensor(29, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_logits = model(x_new)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(y_pred_logits)\n",
    "\n",
    "y_pred = y_pred_logits.argmax(dim=1)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376e880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllibraries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
