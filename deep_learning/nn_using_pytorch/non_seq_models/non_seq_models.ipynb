{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f50c2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset , DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c12f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f19c4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other libraries \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e4c8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31c2836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scale\n",
    "\n",
    "scale_data = StandardScaler()\n",
    "housing_data = scale_data.fit_transform(housing.data)\n",
    "\n",
    "scale_target = StandardScaler()\n",
    "housing_target= scale_target.fit_transform(housing.target.reshape(-1 , 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4eb11900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data splittinh\n",
    "\n",
    "x_train_full , x_test , y_train_full , y_test = train_test_split(housing_data , housing_target ,\n",
    "                                                                  random_state=42 , test_size=0.15)\n",
    "\n",
    "x_train , x_valid , y_train , y_valid = train_test_split(x_train_full , y_train_full ,\n",
    "                                                         random_state=42 , test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24010329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensors \n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "x_valid = torch.FloatTensor(x_valid)\n",
    "\n",
    "y_train = torch.FloatTensor(y_train).reshape(-1  ,1 )\n",
    "y_test = torch.FloatTensor(y_test).reshape(-1  ,1 )\n",
    "y_valid = torch.FloatTensor(y_valid).reshape(-1  ,1 )\n",
    "\n",
    "\n",
    "\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b11320ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self , n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features , 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50 , 40),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(40 + n_features , 1)\n",
    "        \n",
    "    def forward(self , x):\n",
    "        deep_output = self.deep_stack(x)\n",
    "        wide_and_deep = torch.concat([x , deep_output] , dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a95881ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "712a332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model , optimizer ,criterion ,train_loader , n_epoch):\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        for x_batch , y_batch in train_loader:\n",
    "            model.train()\n",
    "            #on gpu\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            #forward\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            #loss\n",
    "            loss =  criterion(y_pred , y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            #backward\n",
    "            loss.backward()\n",
    "            \n",
    "            #optimizer \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        mean_loss = total_loss/len(train_loader)\n",
    "        \n",
    "        print(f\"Epoch : {epoch + 1}/{n_epoch}\",\n",
    "              f\"Loss : {mean_loss:.4f}\")\n",
    "        \n",
    "        \n",
    "def evaluate(model , metrics , valid_loader):\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    with torch.no_grad():\n",
    "        for x_batch , y_batch in valid_loader:\n",
    "            x_batch , y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            metrics.update(y_pred , y_batch)\n",
    "    \n",
    "    return metrics.compute()\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8004a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/20 Loss : 0.8552\n",
      "Epoch : 2/20 Loss : 0.5839\n",
      "Epoch : 3/20 Loss : 0.5115\n",
      "Epoch : 4/20 Loss : 0.4899\n",
      "Epoch : 5/20 Loss : 0.4714\n",
      "Epoch : 6/20 Loss : 0.4616\n",
      "Epoch : 7/20 Loss : 0.4533\n",
      "Epoch : 8/20 Loss : 0.4458\n",
      "Epoch : 9/20 Loss : 0.4404\n",
      "Epoch : 10/20 Loss : 0.4340\n",
      "Epoch : 11/20 Loss : 0.4285\n",
      "Epoch : 12/20 Loss : 0.4252\n",
      "Epoch : 13/20 Loss : 0.4213\n",
      "Epoch : 14/20 Loss : 0.4153\n",
      "Epoch : 15/20 Loss : 0.4136\n",
      "Epoch : 16/20 Loss : 0.4094\n",
      "Epoch : 17/20 Loss : 0.4058\n",
      "Epoch : 18/20 Loss : 0.4025\n",
      "Epoch : 19/20 Loss : 0.4024\n",
      "Epoch : 20/20 Loss : 0.4003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6277, device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = WideAndDeep(n_features).to(device)\n",
    "learning_rate = 0.002\n",
    "n_epoch = 20\n",
    "\n",
    "train_dataset = TensorDataset(x_train , y_train)\n",
    "train_loader = DataLoader(train_dataset , batch_size=100 , pin_memory=True , shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(x_valid , y_valid)\n",
    "valid_loader = DataLoader(valid_dataset , batch_size=100 , pin_memory=True , shuffle=True)\n",
    "\n",
    "mse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model.parameters() , lr=learning_rate)\n",
    "\n",
    "train(model , optimizer , loss , train_loader , n_epoch )\n",
    "evaluate(model , mse , valid_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b201f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/20 Loss : 0.8552 Train Metrics : 0.9266 valid metrics : 0.8128\n",
      "Epoch : 2/20 Loss : 0.5837 Train Metrics : 0.7652 valid metrics : 0.7333\n",
      "Epoch : 3/20 Loss : 0.5117 Train Metrics : 0.7161 valid metrics : 0.7053\n",
      "Epoch : 4/20 Loss : 0.4852 Train Metrics : 0.6973 valid metrics : 0.6924\n",
      "Epoch : 5/20 Loss : 0.4721 Train Metrics : 0.6873 valid metrics : 0.6836\n",
      "Epoch : 6/20 Loss : 0.4614 Train Metrics : 0.6801 valid metrics : 0.6771\n",
      "Epoch : 7/20 Loss : 0.4553 Train Metrics : 0.6740 valid metrics : 0.6710\n",
      "Epoch : 8/20 Loss : 0.4477 Train Metrics : 0.6687 valid metrics : 0.6658\n",
      "Epoch : 9/20 Loss : 0.4398 Train Metrics : 0.6638 valid metrics : 0.6608\n",
      "Epoch : 10/20 Loss : 0.4355 Train Metrics : 0.6593 valid metrics : 0.6564\n",
      "Epoch : 11/20 Loss : 0.4286 Train Metrics : 0.6554 valid metrics : 0.6524\n",
      "Epoch : 12/20 Loss : 0.4239 Train Metrics : 0.6518 valid metrics : 0.6486\n",
      "Epoch : 13/20 Loss : 0.4191 Train Metrics : 0.6485 valid metrics : 0.6453\n",
      "Epoch : 14/20 Loss : 0.4162 Train Metrics : 0.6454 valid metrics : 0.6420\n",
      "Epoch : 15/20 Loss : 0.4122 Train Metrics : 0.6428 valid metrics : 0.6392\n",
      "Epoch : 16/20 Loss : 0.4099 Train Metrics : 0.6401 valid metrics : 0.6366\n",
      "Epoch : 17/20 Loss : 0.4063 Train Metrics : 0.6376 valid metrics : 0.6342\n",
      "Epoch : 18/20 Loss : 0.4050 Train Metrics : 0.6357 valid metrics : 0.6319\n",
      "Epoch : 19/20 Loss : 0.4005 Train Metrics : 0.6336 valid metrics : 0.6298\n",
      "Epoch : 20/20 Loss : 0.3988 Train Metrics : 0.6320 valid metrics : 0.6277\n"
     ]
    }
   ],
   "source": [
    "def train_and_eval(model , optimizer , criterion  , metric , train_loader , \n",
    "                   valid_loader , n_epoch ):\n",
    "    \n",
    "    history = {\"train_metrics\" : [] , \"val_metrics\" : [] , \"loss\" : []}\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        metric.reset()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for x_batch , y_batch in train_loader:\n",
    "            model.train()\n",
    "            x_batch , y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            \n",
    "            #forward \n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            #loss  \n",
    "            loss = criterion(y_pred , y_batch)\n",
    "            total_loss+= loss.item()\n",
    "            \n",
    "            #optimzer and backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            metric.update(y_pred , y_batch)\n",
    "        \n",
    "        mean_loss = total_loss/len(train_loader)\n",
    "        history[\"loss\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            metric.reset()\n",
    "            \n",
    "            for x_valid_batch , y_valid_batch in valid_loader:\n",
    "                x_valid_batch , y_valid_batch = x_valid_batch.to(device) , y_valid_batch.to(device)\n",
    "                y_pred = model(x_valid_batch)\n",
    "                metric.update(y_pred , y_valid_batch)\n",
    "            \n",
    "        history[\"val_metrics\"].append(metric.compute().item())\n",
    "        \n",
    "        print(f\"Epoch : {epoch+1}/{n_epoch}\",\n",
    "              f\"Loss : {history['loss'][-1]:.4f}\",\n",
    "              f\"Train Metrics : {history['train_metrics'][-1]:.4f}\",\n",
    "              f\"valid metrics : {history['val_metrics'][-1]:.4f}\")\n",
    "        \n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = WideAndDeep(n_features).to(device)\n",
    "learning_rate = 0.002\n",
    "n_epoch = 20\n",
    "\n",
    "train_dataset = TensorDataset(x_train , y_train)\n",
    "train_loader = DataLoader(train_dataset , batch_size=100 , pin_memory=True , shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(x_valid , y_valid)\n",
    "valid_loader = DataLoader(valid_dataset , batch_size=100 , pin_memory=True , shuffle=True)\n",
    "\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model.parameters() , lr=learning_rate)\n",
    "\n",
    "history = train_and_eval(model , optimizer , loss , rmse , train_loader , \n",
    "               valid_loader , n_epoch)\n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e63998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d176a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllibraries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
